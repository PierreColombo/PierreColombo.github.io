---
title: "Guiding attention in Sequence-to-sequence models for Dialogue Act prediction"
collection: talks
type: "Poster Presentation"
permalink: /talks/2020-02-09-talk
venue: "AAAI 2020"
date: 2020-02-09
location: "New York, USA"
---
<b>This is a joint work with [Emile Chapuis](https://emilechapuis.github.io/). [Paper](https://ojs.aaai.org//index.php/AAAI/article/view/6259){: .btn } </b>
The task of predicting dialog acts (DA) based on conversational dialog is a key component in the development of conversational agents. Accurately predicting DAs requires a precise modeling of both the conversation and the global tag dependencies. We leverage seq2seq approaches widely adopted
in Neural Machine Translation (NMT) to improve the modelling of tag sequentiality. Seq2seq models are known to learn
complex global dependencies while currently proposed approaches using linear conditional random fields (CRF) only
model local tag dependencies. In this work, we introduce a
seq2seq model tailored for DA classification using: a hierarchical encoder, a novel guided attention mechanism and
beam search applied to both training and inference. Compared to the state of the art our model does not require handcrafted features and is trained end-to-end. Furthermore, the
proposed approach achieves an unmatched accuracy score of
85% on SwDA, and state-of-the-art accuracy score of 91.6%
on MRDA.